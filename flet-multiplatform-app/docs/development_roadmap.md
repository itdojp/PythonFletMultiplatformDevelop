# Flet マルチプラットフォーム開発テンプレート 開発ロードマップ

## フェーズ1: コア機能の確立

### 1.1 プロジェクト構造の整備

- [ ] ディレクトリ構造の最適化
- [ ] 基本設定ファイルのセットアップ
  - `pyproject.toml` の設定
  - 開発用依存関係の定義
  - コードフォーマット設定 (black, isort)

### 1.2 開発環境構築

- [ ] Docker開発環境の整備
  - マルチステージビルドの実装
  - ホットリロード設定
  - 開発用/本番環境の分離
- [ ] 開発ツールのセットアップ
  - デバッグ設定 (VS Code)
  - テスト環境の構築

## フェーズ2: コアライブラリ開発

### 2.1 ユーティリティモジュール

- [x] ロギングユーティリティ
- [x] 設定管理
- [x] エラーハンドリング
- [x] バリデーション

### 2.2 共通コンポーネント

- [x] ベースウィジェット
- [x] テーマ管理
- [x] ルーティングシステム
- [x] 状態管理

## フェーズ3: 開発者体験の向上

### 3.1 開発ツール

- [x] コードジェネレーター
- [x] コンポーネントスキャフォールド
- [x] プロジェクト初期化スクリプト

### 3.2 テスト環境

- [x] テストユーティリティ
- [x] モックサーバー
- [x] UIテストフレームワーク

## フェーズ4: ドキュメンテーション

### 4.1 技術文書

- [x] アーキテクチャ設計書
- [x] APIリファレンス
- [x] チュートリアル

### 4.2 開発ガイド

- [x] コーディング規約
- [x] コンポーネント開発ガイド
- [x] テスト戦略

## フェーズ5: デプロイメント

### 5.1 ビルドシステム

- [x] マルチプラットフォームビルド
- [x] アセット最適化
- [x] バージョニング

### 5.2 デプロイメント

- [x] CI/CDパイプライン
- [x] アプリストア提出用スクリプト
- [x] 更新システム

## フェーズ6: サンプルアプリケーション

### 6.1 デモアプリ

- [x] 認証フロー
- [x] CRUD操作
- [x] オフライン機能

### 6.2 実装例

- [x] チャットアプリ
- [x] ダッシュボード
- [x] フォームアプリケーション

## フェーズ7: 品質向上と最適化

### 7.1 テストカバレッジの向上

- [ ] テストカバレッジ目標の設定（バックエンド: 85%以上、フロントエンド: 70%以上）
  - `現状の課題:` バックエンド、フロントエンド共に現状のカバレッジは未計測。Fletのテスト作成の難易度やUI部分のテスト自動化範囲も考慮し、目標値の再検討が必要な可能性あり。
  - `サブタスク:`
    - `[ ] 現状のテストカバレッジを計測・可視化する。（`pytest-cov`結果の詳細分析）`
    - `[ ] バックエンドAPIの主要機能（認証、主要なCRUD操作、ビジネスロジック）のカバレッジを優先的に向上させる。`
    - `[ ] Fletフロントエンドのテスト戦略を具体化し、現実的なカバレッジ目標とテスト手法（単体テスト、UIコンポーネントテストの可能性調査）を定める。`
- [ ] カバレッジレポートの自動生成とCI/CDパイプラインへの統合
  - `現状:` 基本的なレポート生成は`pytest-cov`により設定済み。CIでのアーティファクト保存や閾値チェック連携を強化。
- [ ] カバレッジ閾値の強制（`pytest-cov` の `--cov-fail-under` の活用）
  - `具体的なステップ:` CI/CDパイプラインに `--cov-fail-under=目標値` を設定し、段階的に目標値を引き上げる。
- [ ] カバレッジの可視化（Codecov や Coveralls との連携）
  - `現状:` 未連携。連携によりプルリクエストごとのカバレッジ変動を追跡可能にする。
- [ ] 単体テスト・結合テストの拡充計画策定と実行（特にビジネスロジックと複雑なUIコンポーネント）
- [ ] フロントエンドテスト戦略の具体化（Fletのテストの難易度を考慮し、現実的なカバレッジ目標とテスト手法を再検討）

### 7.2 ドキュメンテーションの充実

- [ ] 既存ユーザー向けドキュメント（Getting Started, チュートリアル, トラブルシューティング）の定期的な見直しと更新、及び内容の統一化
  - `現状の課題:` 各ドキュメント間でPythonバージョン、依存関係のインストール方法、アプリケーションの起動コマンド等の情報に不整合が見られる。これらの情報を最新化し、統一する必要がある。（実施済み・継続対応）
- [ ] バックエンドAPIドキュメントの活用推進（FastAPIによる自動生成OpenAPIドキュメントの周知と利用方法整備）
  - `現状:` FastAPIにより `/docs` `/redoc` が自動生成されている。これを開発者・利用者が活用しやすいように案内を強化。
- [ ] Flet UIコンポーネントのPropsやイベントに関するドキュメント整備手法の確立（例: カスタムDocStringパーサー、または手動でのAPIリファレンス作成）
  - `課題:` Fletのカスタムコンポーネントのインターフェースがコード以外から把握しづらい。
- [ ] コードコメントの充実（Google スタイルドキュストリングの徹底）
  - `目標値:` プロジェクト内の主要モジュール・関数におけるGoogleスタイルDocstring網羅率80%以上。
  - `現状:` Docstringのスタイルや網羅率にばらつきあり。
- [ ] ドキュメントの多言語対応（英語・日本語）
  - `現状の課題:` 英語と日本語のドキュメントが混在しており、翻訳の質や用語の一貫性に改善の余地がある。翻訳レビュープロセスの導入検討。

### 7.3 エラーハンドリングの強化

- [ ] エラーコード体系の標準化（RFC 7807 準拠のエラー応答）
  - `対象:` 主にバックエンドAPI。クライアント側でのエラー処理を容易にするため。
- [ ] エラーログの構造化（JSON フォーマットでの出力）
  - `現状の課題:` ログフォーマットは部分的に標準化されているが（例: Uvicornのアクセスログ等）、アプリケーション全体のログ出力（特にエラーログ）で一貫した構造化JSONフォーマットが適用されているか確認と徹底が必要。
  - `目標:` 全てのアプリケーションログ（特にエラー関連）を構造化JSON形式で出力し、ログ分析ツールでの集計・分析を容易にする。
- [ ] エラー監視・アラートの仕組みの構築（Sentry や Datadog との連携）
  - `具体的なステップ:`
    - `[ ] 主要なエラー監視ツール（Sentry, Datadog, etc.）の機能比較と選定。`
    - `[ ] 選定したツールとの連携プロトタイプを実装し、効果を検証。`
    - `[ ] 本番環境への導入とアラート閾値の設定、通知体制の構築。`
- [ ] リトライ・サーキットブレーカー・バルクヘッドパターンの実装
  - `対象:` 外部サービス連携部分（例: 外部API呼び出し）や、障害が連鎖しやすい箇所（例: データベース接続）を特定し、段階的に導入。
  - `現状:` 未実装。これらのパターンを導入することで、システムの堅牢性を向上させる。
- [ ] Flet UIにおけるユーザーフレンドリーなエラー表示とフィードバック収集機構の検討
  - `課題:` 現状のFlet UIでは、予期せぬエラーが発生した場合のユーザーへの通知方法や、問題報告の手段が標準化されていない。
  - `具体的なステップ:`
    - `[ ] UI上での共通エラーメッセージコンポーネントの設計。`
    - `[ ] エラー発生時のログID表示と、それを用いた問い合わせフローの検討。`
    - `[ ] (オプション) ユーザーからの直接フィードバック送信機能の検討。`

## 開発フロー

1. 各項目を順番に実装
2. 実装後、対応するテストを作成
3. ドキュメントを更新
4. コードレビュー（可能な場合）
5. マージ & リリース

## バージョン管理

- セマンティックバージョニングに従う
- 変更点はCHANGELOG.mdに記録
- タグ付けはリリースごとに行う

## コントリビューションガイドライン

1. 機能ごとにブランチを切る
2. プルリクエストでコードレビューを行う
3. テストカバレッジを維持する
4. ドキュメントを更新する
